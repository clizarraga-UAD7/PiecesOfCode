
# K-means clustering
from random import sample
from sklearn.cluster import KMeans
model = KMeans(n_clusters = 3)
model.fit(samples)
labels = model.predict(samples)
print(labels)

# Cluster labels for new sample
print(new_samples)
new_labels = model.predict(new_samples)
print(new_labels)

import matplotlib as plt
xs = samples[:,0] # Sepal length
ys = samples[:,2] # Petal length
plt.scatter(xs, ys, c=labels)
plt.show()

# How many clusters?
from sklearn.cluster import KMeans
# create a model
model = KMeans(n_clusters=3)
# fit model to points
model.fit(points)
labels = model.predict(new_points)
print(labels)

# Inspect your Cluster
import matplotlib.pyplot as plt
xs = samples[:,0] # Sepal length
ys = samples[:,1]
plt.scatter(xs, ys, c=labels, alpha=0.5)
# assign cluster centers 
centroids = model.cluster_centers_
# assign the columns of centroids
centroids_x = centroids[:,0]
centroids_y = centroids[:,1]
plt.scatter(centroids_x, centroids_y, marker='D', s=50)
plt.show 


# Evaluating a Clustering
import pandas as pd
df=pd.DataFrame({'labels' : labels, 'species' : species})
ct = pd.crosstab(df['labels'], df['species'])
print(ct)

# Intertial measures clustering quality
# Measures how spread the clusters are (lower is better)
# Distance from each sample to centroid of its cluster
# After fit(), available as attribute inertia_
# k-means attempts to minimize inertia when choosing cluster
from sklearn.cluster import KMeans
model = KMeans(n_clusters = 3)
model.fit(samples)
print(model.inertia_)

# Samples of grain (UCI ML)
ks = range(1,6)
inertias = []
for k in ks:
    model = KMeans(n_clusters = k)
    model.fit(sample)
    inertias.append(model.inertia_)
    plt.plot(ks, inertial, '-o')
    plt.xlabel('Number of clusters, k')
    plt.ylabel('inertia')
    plt.xtics(ks)
    plt.show()

    

